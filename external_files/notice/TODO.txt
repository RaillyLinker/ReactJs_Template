[TODO]
(1단계)
- 템플릿 샘플 : 가로 스크롤
    1. 광고판 같은 무한 스크롤 좌우 버튼, 아래 버튼 존재, 한 아이템이 한 페이지 차지 및 버튼으로만 이동 가능, 시간 지나면 자동 이동, 
    2. 클릭으로 드래그 가능한 무한 가로 스크롤, 
    3. 휠로 이동 가능한 세로 스크롤과 드래그로 이동 가능한 가로 스크롤 복합
    위 모든 스크롤들의 위치 상태 저장
- 미디어 샘플 : Gif 프레임 분리 -> 이미지 프레임 리스트를 Gif 로 합치기
- 미디어 샘플 : webp 프레임 분리 -> 이미지 프레임 리스트를 webp 로 합치기
- 미디어 샘플 : avif 프레임 분리 -> 이미지 프레임 리스트를 avif 로 합치기
- 기타 샘플 : 지도 샘플
- 기타 샘플 : 게시판 글 작성(Draft.js, Quill, TinyMCE, CKEditor 중에 하나 고르기)

(2단계)
- 이미지 리사이징 개선 : gif, webp, avif 움직이도록 (프레임별 분리하고 리사이징 하고 결합)
- 네트워크 샘플 : webrtc
- 미디어 샘플 : 동영상 자르기
- 미디어 샘플 : 동영상을 gif로 변경
- 미디어 샘플 : gif를 동영상으로 변경
- 계정 샘플 (전역 변수에 계정 정보 저장하고, 페이지 복귀시 리랜더링 되는지 확인)
- 기타 샘플 : 이미지 선택 샘플 (로컬에서 이미지 선택시 썸네일 표시. 누르면 전체 표시)
- 기타 샘플 : 동영상 선택 샘플 (로컬에서 영상 선택시 썸네일 표시. 누르면 재생됨)
- 기타 샘플 : pdf 생성(게시판 글 작성 샘플에 작성된 글에 대한 옵션)

(3단계)
- 미디어 샘플 : Gif 재생 조작 샘플 - 호버링하면 재생, 벗어나면 정지, Gif 를 동영상으로 만들고, 그것을 비디오로 표시한 후 이것으로 재생시간 조작 가능
- 네트워크 소켓 샘플 : 채팅(계정과 연동하여 멀티 채팅 - 서버랑 같이 작업)

(4단계)
- 네트워크 소켓 샘플 : 화상 채팅(채팅 샘플과 연동)

(시간 날 때)
- next js 로 바꾸는 방법
- electron 데스크톱 앱
- 오디오 / 비디오 다운로드 방지 처리
    미디어 스트리밍 프로토콜 사용 (HLS 또는 DASH)
    미디어 파일을 일반 HTTP로 제공하는 대신, HLS (HTTP Live Streaming) 또는 MPEG-DASH와 같은 스트리밍 프로토콜을 사용하는 것이 좋습니다. 
    이 프로토콜들은 비디오를 작은 조각들로 스트리밍하며, 사용자가 전체 비디오 파일을 쉽게 다운로드할 수 없게 만듭니다.
    예를 들어, HLS 스트리밍을 React에서 사용하려면 video.js나 hls.js와 같은 라이브러리를 사용할 수 있습니다.
- 모바일 환경에서 확인하기 : 페이지 전부 반응형으로 만들기 및 CSS 개선
- 게임 샘플 추가 : 테트리스, 리듬게임, 퐁, 벽돌깨기, 크롬 공룡게임, 지뢰찾기, 갤러그

- 미디어 샘플 : 캠 영상 촬영 및 녹화
(캠 샘플)
import React, { useState, useRef, useEffect } from 'react';

const App: React.FC = () => {
  const [isCameraOn, setIsCameraOn] = useState(false);
  const [isMirrored, setIsMirrored] = useState(false);
  const [isRecording, setIsRecording] = useState(false);
  const [error, setError] = useState<string | null>(null);
  const videoRef = useRef<HTMLVideoElement>(null);
  const mediaRecorderRef = useRef<MediaRecorder | null>(null);
  const recordedChunks = useRef<Blob[]>([]);
  let stream: MediaStream | null = null;

  useEffect(() => {
    if (isCameraOn) {
      startCamera();
    } else {
      stopCamera();
    }

    // 페이지를 떠나거나 뒤로 가기 시 카메라 정리
    return () => {
      stopCamera();
    };
  }, [isCameraOn]);

  const startCamera = async () => {
    try {
      stream = await navigator.mediaDevices.getUserMedia({ video: true });
      if (videoRef.current) {
        videoRef.current.srcObject = stream;
      }
      setError(null);

      stream.getTracks()[0].onended = () => {
        handleCameraDisconnected();
      };
    } catch (err) {
      setError('Cannot access the camera. Please check your device.');
    }
  };

  const stopCamera = () => {
    if (videoRef.current?.srcObject) {
      const stream = videoRef.current.srcObject as MediaStream;
      stream.getTracks().forEach(track => track.stop());
      videoRef.current.srcObject = null;
    }
    if (stream) {
      stream.getTracks().forEach(track => track.stop());
      stream = null;
    }
    setIsRecording(false); // 녹화 상태를 초기화
    setIsMirrored(false); // 좌우반전 상태를 초기화
  };

  const handleMirrorToggle = () => {
    setIsMirrored(!isMirrored);
  };

  const handleCapture = () => {
    if (videoRef.current) {
      const canvas = document.createElement('canvas');
      canvas.width = videoRef.current.videoWidth;
      canvas.height = videoRef.current.videoHeight;
      const context = canvas.getContext('2d');
      if (context) {
        if (isMirrored) {
          context.translate(canvas.width, 0);
          context.scale(-1, 1);
        }
        context.drawImage(videoRef.current, 0, 0, canvas.width, canvas.height);
        const dataUrl = canvas.toDataURL('image/png');
        const link = document.createElement('a');
        link.href = dataUrl;
        link.download = 'capture.png';
        link.click();
      }
    }
  };

  const handleRecordToggle = () => {
    if (isRecording) {
      mediaRecorderRef.current?.stop();
    } else {
      startRecording();
    }
    setIsRecording(!isRecording);
  };

  const startRecording = () => {
    if (videoRef.current?.srcObject) {
      const stream = videoRef.current.srcObject as MediaStream;
      mediaRecorderRef.current = new MediaRecorder(stream, { mimeType: 'video/webm' });

      mediaRecorderRef.current.ondataavailable = event => {
        if (event.data.size > 0) {
          recordedChunks.current.push(event.data);
        }
      };

      mediaRecorderRef.current.onstop = () => {
        const blob = new Blob(recordedChunks.current, { type: 'video/webm' });
        recordedChunks.current = [];
        const url = URL.createObjectURL(blob);
        const link = document.createElement('a');
        link.href = url;
        link.download = 'recording.webm';
        link.click();
        URL.revokeObjectURL(url);
      };

      mediaRecorderRef.current.start();
    }
  };

  const handleCameraDisconnected = () => {
    setIsCameraOn(false);
    setIsRecording(false);
    setError('Camera has been disconnected.');
  };

  return (
    <div style={{ padding: '20px' }}>
      <button onClick={() => setIsCameraOn(!isCameraOn)}>
        {isCameraOn ? 'Camera Off' : 'Camera On'}
      </button>

      <div style={{ marginTop: '20px', width: '40rem', height: '40rem', border: '2px solid black', position: 'relative' }}>
        {error && <div style={{ color: 'red', position: 'absolute', top: '50%', left: '50%', transform: 'translate(-50%, -50%)' }}>{error}</div>}
        <video
          ref={videoRef}
          style={{ width: '100%', height: '100%', transform: isMirrored ? 'scaleX(-1)' : 'none' }}
          autoPlay
          playsInline
        />
      </div>

      {isCameraOn && !error && (
        <div style={{ marginTop: '10px' }}>
          <button onClick={handleMirrorToggle}>
            {isMirrored ? 'Unmirror' : 'Mirror'}
          </button>
          <button onClick={handleCapture}>Capture</button>
          <button onClick={handleRecordToggle}>
            {isRecording ? 'Stop Recording' : 'Start Recording'}
          </button>
        </div>
      )}
    </div>
  );
};

export default App;
